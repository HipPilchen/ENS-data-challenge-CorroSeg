{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hippolyte/anaconda3/envs/ens_data/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from model import get_model\n",
    "from dataloader import CorroSeg\n",
    "from utils import iou_score,  RollTransform\n",
    "from losses import SoftIoULoss, FocalLoss\n",
    "from dataloader import CorroSeg, CorroSegDataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np \n",
    "import os\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_corrosion = 7/100\n",
    "def train(args):\n",
    "\n",
    " \n",
    "    if args.experiment_name is None:\n",
    "            args.experiment_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            \n",
    "    if(args.wandb):\n",
    "        wandb.init(\n",
    "            name=args.experiment_name,\n",
    "            id=args.wandb_id,\n",
    "            entity=args.wandb_entity,\n",
    "            project=\"corroseg\",\n",
    "        )\n",
    "        \n",
    "        wandb.config = {\n",
    "            \"architecture\":args.model_name,\n",
    "            \"epochs\":args.num_epochs,\n",
    "            \"learning_rate\":args.learning_rate,\n",
    "        }\n",
    "        \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = get_model(model_name=args.model_name, backbone_name=args.backbone, backbone_pretrained=args.pretrained).to(device)\n",
    "    \n",
    "\n",
    "    # Possible transforms: transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(), t\n",
    "        \n",
    "    transform_img = [None,\n",
    "        transforms.RandomHorizontalFlip(1),\n",
    "        transforms.RandomVerticalFlip(1),RollTransform(),\n",
    "        transforms.Compose([transforms.RandomVerticalFlip(1),transforms.RandomHorizontalFlip(1)]),]\n",
    "\n",
    " \n",
    "    \n",
    "    corro_seg = CorroSeg('data', 'y_train.csv', shuffle = True,\n",
    "                 batch_size = args.batch_size, valid_ratio = args.valid_ratio, transform_img=transform_img,  \n",
    "                 transform_test=None, test_params={'batch_size': args.batch_size, 'shuffle': False})\n",
    "    train_loader, val_loader, test_loader = corro_seg.get_loaders()\n",
    "    print(\"Data loaded\")\n",
    "    # print(\"Number of training images: \", len(train_loader.dataset))\n",
    "    # print(\"Number of validation images: \", len(val_loader.dataset))\n",
    "    # print(\"Number of test images: \", len(test_loader.dataset))\n",
    "\n",
    "    # Loss function and optimizer definition\n",
    "    if args.criterion == 'bce':\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    elif args.criterion == 'iou':\n",
    "        criterion = SoftIoULoss()\n",
    "    elif args.criterion == 'focal':\n",
    "        criterion = FocalLoss(args.gamma,args.alpha)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "\n",
    "\n",
    "    for epoch in tqdm(range(args.num_epochs)):\n",
    "        # Defreezing strategy\n",
    "        if args.defreezing_strategy and (epoch % args.unfreeze_at_epoch == 0):\n",
    "            layers_to_unfreeze = (epoch // args.unfreeze_at_epoch) * args.layers_to_unfreeze_each_time\n",
    "            model.unfreeze_layers(layers_to_unfreeze)\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_iou = 0.0\n",
    "        \n",
    "        for image, mask, well in tqdm(train_loader):\n",
    "            if args.model_need_GRAY:\n",
    "                image = torch.mean(image, dim=1, keepdim=True)\n",
    "            mask = torch.mean(mask, dim=1, keepdim = True)\n",
    "            optimizer.zero_grad()\n",
    "            image = image.to(device)  # Move image to device\n",
    "            mask = mask.to(device)  # Move mask to device\n",
    "            outputs = model(image)\n",
    "            print('outputs',outputs.shape)\n",
    "            print('mask',mask.shape)\n",
    "\n",
    "            loss = criterion(outputs, mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * image.size(0)\n",
    "            # Apply threshold to get binary predictions\n",
    "            preds = (outputs - args.threshold).round()\n",
    "            train_iou += iou_score(preds, mask).item() * image.size(0)\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_iou /= len(train_loader.dataset)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_iou = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for image, mask, well in tqdm(val_loader):\n",
    "                if args.model_need_GRAY:\n",
    "                    image = torch.mean(image, dim=1, keepdim=True)\n",
    "                mask = torch.mean(mask, dim=1, keepdim = True)\n",
    "                image = image.to(device)  # Move image to device\n",
    "                mask = mask.to(device)  # Move mask to device\n",
    "                outputs = model(image)\n",
    "                outputs = outputs.detach()  # Detach outputs from the computation graph\n",
    "                loss = criterion(outputs, mask)\n",
    "                val_loss += loss.item() * image.size(0)\n",
    "                # Apply threshold to get binary predictions\n",
    "                preds = (outputs - args.threshold).round()\n",
    "                val_iou += iou_score(preds, mask).item() * image.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_iou /= len(val_loader.dataset)\n",
    "        \n",
    "        # Logging to Weights and Biases\n",
    "        if(args.wandb):\n",
    "            wandb.log({'Train Loss': train_loss, 'Train IoU': train_iou,\n",
    "                    'Validation Loss': val_loss, 'Validation IoU': val_iou}, step=epoch)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{args.num_epochs}, Train Loss: {train_loss:.4f}, Train IoU: {train_iou:.4f}, Validation Loss: {val_loss:.4f}, Validation IoU: {val_iou:.4f}')\n",
    "        \n",
    "    # Testing phase\n",
    "    model.eval()\n",
    "    predicted_masks = []  # List to store predicted masks\n",
    "    with torch.no_grad():\n",
    "        for image, _, _ in test_loader:  # Ignore the masks in the test loader\n",
    "            if args.model_need_GRAY:\n",
    "                image = torch.mean(image, dim=1, keepdim=True)\n",
    "\n",
    "            image = image.to(device)\n",
    "            output = model(image).detach()\n",
    "            preds = output > args.threshold  # Apply threshold to get binary predictions\n",
    "            preds = preds.int()\n",
    "\n",
    "            # Check the unique values and values less than -100\n",
    "            unique_values = torch.unique(image)\n",
    "            # if len(unique_values) < 10 or torch.any(image < -100):\n",
    "            if torch.any(image < -100):\n",
    "                preds = torch.zeros_like(preds).int()  # Reset preds to zeros if conditions are met\n",
    "\n",
    "            # Ensure consistent shape for all flattened masks\n",
    "            flattened_mask = preds.cpu().numpy().reshape(-1, 36*36)  # Explicitly specify the flattened shape\n",
    "            predicted_masks.extend(flattened_mask)\n",
    "\n",
    "    # Save predicted masks to a CSV file\n",
    "    predicted_masks = np.vstack(predicted_masks)  # Stack the list of arrays into a single 2D array\n",
    "    df = pd.DataFrame(predicted_masks)\n",
    "\n",
    "    files = [f.replace('.npy','') for f in os.listdir('data/processed/images_test')]\n",
    "    df.index = files\n",
    "\n",
    "    prediction_path = \"data/predictions/submission_\" + args.experiment_name + '.csv'\n",
    "    df.to_csv(prediction_path, index=True)\n",
    "\n",
    "    print(\"Predicted masks saved to predicted_masks.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({'num_epochs': 4, 'criterion': 'iou', 'batch_size': 64, 'valid_ratio': 0.1, \n",
    "          'model_name': 'jacard_unet', 'backbone': 'efficientnet-v2-m', 'learning_rate': 2e-5, \n",
    "          'threshold': 0.5, 'defreezing_strategy': False, 'unfreeze_at_epoch': 0, \n",
    "          'layers_to_unfreeze_each_time': 100, 'weight_decay': 0.01, 'gamma': 3,\n",
    "          'experiment_name': 'test', 'wandb': False, 'wandb_id': None, 'wandb_entity': None,\n",
    "          'output_dir': 'wandb', 'model_need_GRAY':False, 'pretrained':True, 'alpha':0.25})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1 torch.Size([64, 16, 36, 36])\n",
      "C1bis torch.Size([64, 16, 36, 36])\n",
      "P1 torch.Size([64, 16, 18, 18])\n",
      "C2 torch.Size([64, 32, 18, 18])\n",
      "C2bis torch.Size([64, 32, 18, 18])\n",
      "C3bis torch.Size([64, 64, 9, 9])\n",
      "UP8 torch.Size([64, 32, 18, 18])\n",
      "C8 torch.Size([64, 32, 18, 18])\n",
      "C8bis torch.Size([64, 32, 18, 18])\n",
      "UP9 torch.Size([64, 16, 36, 36])\n",
      "C9 torch.Size([64, 16, 36, 36])\n",
      "C9bis torch.Size([64, 16, 36, 36])\n",
      "outputs torch.Size([64, 1, 36, 36])\n",
      "mask torch.Size([64, 1, 36, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1 torch.Size([64, 16, 36, 36])\n",
      "C1bis torch.Size([64, 16, 36, 36])\n",
      "P1 torch.Size([64, 16, 18, 18])\n",
      "C2 torch.Size([64, 32, 18, 18])\n",
      "C2bis torch.Size([64, 32, 18, 18])\n",
      "C3bis torch.Size([64, 64, 9, 9])\n",
      "UP8 torch.Size([64, 32, 18, 18])\n",
      "C8 torch.Size([64, 32, 18, 18])\n",
      "C8bis torch.Size([64, 32, 18, 18])\n",
      "UP9 torch.Size([64, 16, 36, 36])\n",
      "C9 torch.Size([64, 16, 36, 36])\n",
      "C9bis torch.Size([64, 16, 36, 36])\n",
      "outputs torch.Size([64, 1, 36, 36])\n",
      "mask torch.Size([64, 1, 36, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1 torch.Size([64, 16, 36, 36])\n",
      "C1bis torch.Size([64, 16, 36, 36])\n",
      "P1 torch.Size([64, 16, 18, 18])\n",
      "C2 torch.Size([64, 32, 18, 18])\n",
      "C2bis torch.Size([64, 32, 18, 18])\n",
      "C3bis torch.Size([64, 64, 9, 9])\n",
      "UP8 torch.Size([64, 32, 18, 18])\n",
      "C8 torch.Size([64, 32, 18, 18])\n",
      "C8bis torch.Size([64, 32, 18, 18])\n",
      "UP9 torch.Size([64, 16, 36, 36])\n",
      "C9 torch.Size([64, 16, 36, 36])\n",
      "C9bis torch.Size([64, 16, 36, 36])\n",
      "outputs torch.Size([64, 1, 36, 36])\n",
      "mask torch.Size([64, 1, 36, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1 torch.Size([64, 16, 36, 36])\n",
      "C1bis torch.Size([64, 16, 36, 36])\n",
      "P1 torch.Size([64, 16, 18, 18])\n",
      "C2 torch.Size([64, 32, 18, 18])\n",
      "C2bis torch.Size([64, 32, 18, 18])\n",
      "C3bis torch.Size([64, 64, 9, 9])\n",
      "UP8 torch.Size([64, 32, 18, 18])\n",
      "C8 torch.Size([64, 32, 18, 18])\n",
      "C8bis torch.Size([64, 32, 18, 18])\n",
      "UP9 torch.Size([64, 16, 36, 36])\n",
      "C9 torch.Size([64, 16, 36, 36])\n",
      "C9bis torch.Size([64, 16, 36, 36])\n",
      "outputs torch.Size([64, 1, 36, 36])\n",
      "mask torch.Size([64, 1, 36, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1 torch.Size([64, 16, 36, 36])\n",
      "C1bis torch.Size([64, 16, 36, 36])\n",
      "P1 torch.Size([64, 16, 18, 18])\n",
      "C2 torch.Size([64, 32, 18, 18])\n",
      "C2bis torch.Size([64, 32, 18, 18])\n",
      "C3bis torch.Size([64, 64, 9, 9])\n",
      "UP8 torch.Size([64, 32, 18, 18])\n",
      "C8 torch.Size([64, 32, 18, 18])\n",
      "C8bis torch.Size([64, 32, 18, 18])\n",
      "UP9 torch.Size([64, 16, 36, 36])\n",
      "C9 torch.Size([64, 16, 36, 36])\n",
      "C9bis torch.Size([64, 16, 36, 36])\n",
      "outputs torch.Size([64, 1, 36, 36])\n",
      "mask torch.Size([64, 1, 36, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1 torch.Size([64, 16, 36, 36])\n",
      "C1bis torch.Size([64, 16, 36, 36])\n",
      "P1 torch.Size([64, 16, 18, 18])\n",
      "C2 torch.Size([64, 32, 18, 18])\n",
      "C2bis torch.Size([64, 32, 18, 18])\n",
      "C3bis torch.Size([64, 64, 9, 9])\n",
      "UP8 torch.Size([64, 32, 18, 18])\n",
      "C8 torch.Size([64, 32, 18, 18])\n",
      "C8bis torch.Size([64, 32, 18, 18])\n",
      "UP9 torch.Size([64, 16, 36, 36])\n",
      "C9 torch.Size([64, 16, 36, 36])\n",
      "C9bis torch.Size([64, 16, 36, 36])\n",
      "outputs torch.Size([64, 1, 36, 36])\n",
      "mask torch.Size([64, 1, 36, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1 torch.Size([64, 16, 36, 36])\n",
      "C1bis torch.Size([64, 16, 36, 36])\n",
      "P1 torch.Size([64, 16, 18, 18])\n",
      "C2 torch.Size([64, 32, 18, 18])\n",
      "C2bis torch.Size([64, 32, 18, 18])\n",
      "C3bis torch.Size([64, 64, 9, 9])\n",
      "UP8 torch.Size([64, 32, 18, 18])\n",
      "C8 torch.Size([64, 32, 18, 18])\n",
      "C8bis torch.Size([64, 32, 18, 18])\n",
      "UP9 torch.Size([64, 16, 36, 36])\n",
      "C9 torch.Size([64, 16, 36, 36])\n",
      "C9bis torch.Size([64, 16, 36, 36])\n",
      "outputs torch.Size([64, 1, 36, 36])\n",
      "mask torch.Size([64, 1, 36, 36])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/657 [00:06<12:37,  1.16s/it]\n",
      "  0%|          | 0/4 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[0;32mIn[2], line 77\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m,mask\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     76\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, mask)\n\u001b[0;32m---> 77\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     80\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m image\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ens_data/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ens_data/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
