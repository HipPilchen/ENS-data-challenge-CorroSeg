{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Hippolyte/anaconda3/envs/ens_data/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "from model import get_model\n",
    "from dataloader import CorroSeg\n",
    "from utils import iou_score,  RollTransform\n",
    "from losses import SoftIoULoss, FocalLoss\n",
    "from dataloader import CorroSeg, CorroSegDataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np \n",
    "import os\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_corrosion = 7/100\n",
    "def train(args):\n",
    "    if args.experiment_name is None:\n",
    "        args.experiment_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "            \n",
    "    if(args.wandb):\n",
    "        wandb.init(\n",
    "            name=args.experiment_name,\n",
    "            id=args.wandb_id,\n",
    "            entity=args.wandb_entity,\n",
    "            project=\"corroseg\",\n",
    "        )\n",
    "        \n",
    "        wandb.config = {\n",
    "            \"architecture\":args.model_name,\n",
    "            \"epochs\":args.num_epochs,\n",
    "            \"learning_rate\":args.learning_rate,\n",
    "        }\n",
    "        \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = get_model(model_name=args.model_name, backbone_name=args.backbone).to(device)\n",
    "    \n",
    "\n",
    "    # Possible transforms: transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(), t\n",
    "        \n",
    "    transform_img = [None,\n",
    "        transforms.RandomHorizontalFlip(1),\n",
    "        transforms.RandomVerticalFlip(1),RollTransform(),\n",
    "        transforms.Compose([transforms.RandomVerticalFlip(1),transforms.RandomHorizontalFlip(1)]),]\n",
    "\n",
    " \n",
    "    \n",
    "    corro_seg = CorroSeg('data', 'y_train.csv', shuffle = True,\n",
    "                 batch_size = args.batch_size, valid_ratio = args.valid_ratio, transform_img=transform_img,  \n",
    "                 transform_test=None, test_params={'batch_size': args.batch_size, 'shuffle': False})\n",
    "    train_loader, val_loader, test_loader = corro_seg.get_loaders()\n",
    "    print(\"Data loaded\")\n",
    "    # print(\"Number of training images: \", len(train_loader.dataset))\n",
    "    # print(\"Number of validation images: \", len(val_loader.dataset))\n",
    "    # print(\"Number of test images: \", len(test_loader.dataset))\n",
    "\n",
    "    # Loss function and optimizer definition\n",
    "    if args.criterion == 'bce':\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    elif args.criterion == 'iou':\n",
    "        criterion = SoftIoULoss()\n",
    "    elif args.criterion == 'focal':\n",
    "        criterion = FocalLoss(args.gamma,1/freq_corrosion)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "\n",
    "\n",
    "    for epoch in tqdm(range(args.num_epochs)):\n",
    "        # Defreezing strategy\n",
    "        if args.defreezing_strategy and (epoch % args.unfreeze_at_epoch == 0):\n",
    "            layers_to_unfreeze = (epoch // args.unfreeze_at_epoch) * args.layers_to_unfreeze_each_time\n",
    "            model.unfreeze_layers(layers_to_unfreeze)\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_iou = 0.0\n",
    "        \n",
    "        for image, mask, well in tqdm(train_loader):\n",
    "            if args.model_need_GRAY:\n",
    "                image = torch.mean(image, dim=1, keepdim=True)\n",
    "            mask = mask.view(-1, 1, 36, 36)\n",
    "            optimizer.zero_grad()\n",
    "            image = image.to(device)  # Move image to device\n",
    "            mask = mask.to(device)  # Move mask to device\n",
    "            outputs = model(image)\n",
    "            loss = criterion(outputs, mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * image.size(0)\n",
    "            # Apply threshold to get binary predictions\n",
    "            preds = (outputs - args.threshold).round()\n",
    "            train_iou += iou_score(preds, mask).item() * image.size(0)\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_iou /= len(train_loader.dataset)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_iou = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for image, mask, well in tqdm(val_loader):\n",
    "                if args.model_need_GRAY:\n",
    "                    image = torch.mean(image, dim=1, keepdim=True)\n",
    "                mask = mask.view(-1, 1, 36, 36)\n",
    "                image = image.to(device)  # Move image to device\n",
    "                mask = mask.to(device)  # Move mask to device\n",
    "                outputs = model(image)\n",
    "                outputs = outputs.detach()  # Detach outputs from the computation graph\n",
    "                loss = criterion(outputs, mask)\n",
    "                val_loss += loss.item() * image.size(0)\n",
    "                # Apply threshold to get binary predictions\n",
    "                preds = (outputs - args.threshold).round()\n",
    "                val_iou += iou_score(preds, mask).item() * image.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_iou /= len(val_loader.dataset)\n",
    "        \n",
    "        # Logging to Weights and Biases\n",
    "        if(args.wandb):\n",
    "            wandb.log({'Train Loss': train_loss, 'Train IoU': train_iou,\n",
    "                    'Validation Loss': val_loss, 'Validation IoU': val_iou}, step=epoch)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{args.num_epochs}, Train Loss: {train_loss:.4f}, Train IoU: {train_iou:.4f}, Validation Loss: {val_loss:.4f}, Validation IoU: {val_iou:.4f}')\n",
    "        \n",
    "    # Testing phase\n",
    "    model.eval()\n",
    "    predicted_masks = []  # List to store predicted masks\n",
    "    with torch.no_grad():\n",
    "        for image, _, _ in test_loader:  # Ignore the masks in the test loader\n",
    "            if args.model_need_GRAY:\n",
    "                image = torch.mean(image, dim=1, keepdim=True)\n",
    "\n",
    "            image = image.to(device)\n",
    "            output = model(image).detach()\n",
    "            preds = output > args.threshold  # Apply threshold to get binary predictions\n",
    "            preds = preds.int()\n",
    "\n",
    "            # Check the unique values and values less than -100\n",
    "            unique_values = torch.unique(image)\n",
    "            # if len(unique_values) < 10 or torch.any(image < -100):\n",
    "            if torch.any(image < -100):\n",
    "                preds = torch.zeros_like(preds).int()  # Reset preds to zeros if conditions are met\n",
    "\n",
    "            # Ensure consistent shape for all flattened masks\n",
    "            flattened_mask = preds.cpu().numpy().reshape(-1, 36*36)  # Explicitly specify the flattened shape\n",
    "            predicted_masks.extend(flattened_mask)\n",
    "\n",
    "    # Save predicted masks to a CSV file\n",
    "    predicted_masks = np.vstack(predicted_masks)  # Stack the list of arrays into a single 2D array\n",
    "    df = pd.DataFrame(predicted_masks)\n",
    "\n",
    "    files = [f.replace('.npy','') for f in os.listdir('data/processed/images_test')]\n",
    "    df.index = files\n",
    "\n",
    "    prediction_path = \"data/predictions/submission_\" + args.experiment_name + '.csv'\n",
    "    df.to_csv(prediction_path, index=True)\n",
    "\n",
    "    print(\"Predicted masks saved to predicted_masks.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({'num_epochs': 4, 'criterion': 'focal', 'batch_size': 64, 'valid_ratio': 0.1, \n",
    "          'model_name': 'cnn', 'backbone': 'efficientnet-v2-m', 'learning_rate': 2e-5, \n",
    "          'threshold': 0.5, 'defreezing_strategy': False, 'unfreeze_at_epoch': 0, \n",
    "          'layers_to_unfreeze_each_time': 100, 'weight_decay': 0.01, 'gamma': 3,\n",
    "          'experiment_name': 'test', 'wandb': False, 'wandb_id': None, 'wandb_entity': None,\n",
    "          'output_dir': 'wandb', 'model_need_GRAY':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mLe noyau s’est bloqué lors de l’exécution du code dans une cellule active ou une cellule précédente. \n",
      "\u001b[1;31mVeuillez vérifier le code dans la ou les cellules pour identifier une cause possible de l’échec. \n",
      "\u001b[1;31mCliquez <a href='https://aka.ms/vscodeJupyterKernelCrash'>ici</a> pour plus d’informations. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "train(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
