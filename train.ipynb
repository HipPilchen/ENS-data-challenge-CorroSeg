{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rz/lpm3rf3n7s5bd6r1dpcpg4w00000gn/T/ipykernel_40057/2335220462.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/Users/lucasgascon/miniforge3/envs/timeseries/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import iou_score\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import wandb\n",
    "from model import get_model\n",
    "from dataloader import CorroSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    if(args.wandb):\n",
    "        wandb.init(\n",
    "            name=args.experiment_name,\n",
    "            id=args.wandb_id,\n",
    "            entity=args.wandb_entity,\n",
    "            project=\"corroseg\",\n",
    "        )\n",
    "        \n",
    "        wandb.config = {\n",
    "            \"architecture\":args.model_name,\n",
    "            \"epochs\":args.num_epochs,\n",
    "            \"learning_rate\":args.learning_rate,\n",
    "        }\n",
    "        \n",
    "    device ='cpu'\n",
    "    model = get_model(args.model_name).to(device)\n",
    "    \n",
    "    corro_seg = CorroSeg('data', 'y_train.csv', shuffle = True,\n",
    "                 batch_size = args.batch_size, valid_ratio = args.valid_ratio, transform_img=None, transform_mask=None, \n",
    "                 transform_test=None, test_params={'batch_size': args.batch_size, 'shuffle': False})\n",
    "    train_loader, val_loader, test_loader = corro_seg.get_loaders()\n",
    "\n",
    "    # Loss function and optimizer definition\n",
    "    criterion = nn.BCELoss()  # Binary cross-entropy loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "\n",
    "    for epoch in tqdm(range(args.num_epochs)):\n",
    "        # Defreezing strategy\n",
    "        if epoch % args.unfreeze_at_epoch == 0:\n",
    "            layers_to_unfreeze = (epoch // args.unfreeze_at_epoch) * args.layers_to_unfreeze_each_time\n",
    "            model.unfreeze_layers(layers_to_unfreeze)\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_iou = 0.0\n",
    "        \n",
    "        for image, mask, well in tqdm(train_loader):\n",
    "            mask = mask.view(-1, 1, 36, 36)\n",
    "            optimizer.zero_grad()\n",
    "            image = image.to(device)  # Move image to device\n",
    "            mask = mask.to(device)  # Move mask to device\n",
    "            outputs = model(image.repeat(1, 3, 1, 1))\n",
    "            loss = criterion(outputs, mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * image.size(0)\n",
    "            preds = outputs > args.threshold  # Apply threshold to get binary predictions\n",
    "            train_iou += iou_score(preds, mask).item() * image.size(0)\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_iou /= len(train_loader.dataset)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_iou = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for image, mask, well in tqdm(val_loader):\n",
    "                mask = mask.view(-1, 1, 36, 36)\n",
    "                image = image.to(device)  # Move image to device\n",
    "                mask = mask.to(device)  # Move mask to device\n",
    "                outputs = model(image.repeat(1, 3, 1, 1))\n",
    "                outputs = outputs.detach()  # Detach outputs from the computation graph\n",
    "                loss = criterion(outputs, mask)\n",
    "                val_loss += loss.item() * image.size(0)\n",
    "                preds = outputs > args.threshold  # Apply threshold to get binary predictions\n",
    "                val_iou += iou_score(preds, mask).item() * image.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_iou /= len(val_loader.dataset)\n",
    "        \n",
    "        # Logging to Weights and Biases\n",
    "        if(args.wandb):\n",
    "            wandb.log({'Train Loss': train_loss, 'Train IoU': train_iou,\n",
    "                    'Validation Loss': val_loss, 'Validation IoU': val_iou}, step=epoch)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{args.num_epochs}, Train Loss: {train_loss:.4f}, Train IoU: {train_iou:.4f}, Validation Loss: {val_loss:.4f}, Validation IoU: {val_iou:.4f}')\n",
    "        \n",
    "    # Testing phase\n",
    "    model.eval()\n",
    "    predicted_masks = []  # List to store predicted masks  \n",
    "    with torch.no_grad():\n",
    "        for image, _ in test_loader:  # Ignore the masks in the test loader\n",
    "            \n",
    "            # Forward pass\n",
    "            image = image.to(device)  # Move image to device\n",
    "            output = model(image.repeat(1, 3, 1, 1)).detach()\n",
    "            pred = output > args.threshold  # Apply threshold to get binary predictions\n",
    "            pred = pred.cpu().numpy()\n",
    "            \n",
    "            # Flatten each 36x36 mask into a 1D array\n",
    "            flattened_mask = pred.reshape(pred.shape[0], -1)\n",
    "            \n",
    "            # Convert predicted masks to numpy arrays\n",
    "            predicted_masks.extend(flattened_mask)\n",
    "    \n",
    "    # Save predicted masks to a CSV file\n",
    "    predicted_masks = np.array(predicted_masks)\n",
    "    df = pd.DataFrame(predicted_masks)\n",
    "    df.to_csv(\"predicted_masks.csv\", index=False)\n",
    "    \n",
    "    print(\"Predicted masks saved to predicted_masks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "        wandb=True,\n",
    "        experiment_name='test1',\n",
    "        output_dir='wandb',\n",
    "        wandb_id=None,\n",
    "        wandb_entity='lucasgascon',\n",
    "        num_epochs=20,\n",
    "        batch_size=1,\n",
    "        valid_ratio=0.1,\n",
    "        model_name='resnet18',\n",
    "        learning_rate=2e-5,\n",
    "        threshold=0.5,\n",
    "        unfreeze_at_epoch=3,\n",
    "        layers_to_unfreeze_each_time=1,\n",
    "        weight_decay=0.01\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlucasgascon\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/lucasgascon/GitHub/ENS-data-challenge-CorroSeg/wandb/run-20240211_162158-ulidllc8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lucasgascon/corroseg/runs/ulidllc8' target=\"_blank\">test1</a></strong> to <a href='https://wandb.ai/lucasgascon/corroseg' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lucasgascon/corroseg' target=\"_blank\">https://wandb.ai/lucasgascon/corroseg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lucasgascon/corroseg/runs/ulidllc8' target=\"_blank\">https://wandb.ai/lucasgascon/corroseg/runs/ulidllc8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasgascon/miniforge3/envs/timeseries/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/lucasgascon/miniforge3/envs/timeseries/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 8397/8397 [10:18<00:00, 13.57it/s]\n",
      "100%|██████████| 933/933 [00:18<00:00, 49.17it/s]\n",
      "  5%|▌         | 1/20 [10:37<3:22:00, 637.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.2460, Train IoU: 0.9106, Validation Loss: 0.6216, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [09:06<00:00, 15.36it/s]\n",
      "100%|██████████| 933/933 [00:17<00:00, 53.00it/s]\n",
      " 10%|█         | 2/20 [20:02<2:58:23, 594.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Train Loss: 0.2492, Train IoU: 0.9106, Validation Loss: 0.7908, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [09:33<00:00, 14.64it/s]\n",
      "100%|██████████| 933/933 [00:16<00:00, 58.20it/s]\n",
      " 15%|█▌        | 3/20 [29:51<2:47:48, 592.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Train Loss: 0.2492, Train IoU: 0.9106, Validation Loss: 0.5091, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [07:32<00:00, 18.57it/s]\n",
      "100%|██████████| 933/933 [00:17<00:00, 54.74it/s]\n",
      " 20%|██        | 4/20 [37:41<2:24:59, 543.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Train Loss: 0.2454, Train IoU: 0.9106, Validation Loss: 0.5359, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [07:27<00:00, 18.77it/s]\n",
      "100%|██████████| 933/933 [00:16<00:00, 56.39it/s]\n",
      " 25%|██▌       | 5/20 [45:25<2:08:44, 514.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Train Loss: 0.2429, Train IoU: 0.9106, Validation Loss: 0.5057, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [07:35<00:00, 18.45it/s]\n",
      "100%|██████████| 933/933 [00:16<00:00, 55.76it/s]\n",
      " 30%|███       | 6/20 [53:16<1:56:43, 500.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Train Loss: 0.2421, Train IoU: 0.9106, Validation Loss: 0.3463, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [08:53<00:00, 15.74it/s]\n",
      "100%|██████████| 933/933 [00:18<00:00, 51.20it/s]\n",
      " 35%|███▌      | 7/20 [1:02:28<1:52:01, 517.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Train Loss: 0.2403, Train IoU: 0.9106, Validation Loss: 0.3003, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [09:47<00:00, 14.30it/s]\n",
      "100%|██████████| 933/933 [00:17<00:00, 52.50it/s]\n",
      " 40%|████      | 8/20 [1:12:33<1:49:00, 545.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Train Loss: 0.2373, Train IoU: 0.9106, Validation Loss: 0.4949, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
