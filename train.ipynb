{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rz/lpm3rf3n7s5bd6r1dpcpg4w00000gn/T/ipykernel_40057/2335220462.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/Users/lucasgascon/miniforge3/envs/timeseries/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils import iou_score\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import wandb\n",
    "from model import get_model\n",
    "from dataloader import CorroSeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    if(args.wandb):\n",
    "        wandb.init(\n",
    "            name=args.experiment_name,\n",
    "            id=args.wandb_id,\n",
    "            entity=args.wandb_entity,\n",
    "            project=\"corroseg\",\n",
    "        )\n",
    "        \n",
    "        wandb.config = {\n",
    "            \"architecture\":args.model_name,\n",
    "            \"epochs\":args.num_epochs,\n",
    "            \"learning_rate\":args.learning_rate,\n",
    "        }\n",
    "        \n",
    "    device ='cpu'\n",
    "    model = get_model(args.model_name).to(device)\n",
    "    \n",
    "    corro_seg = CorroSeg('data', 'y_train.csv', shuffle = True,\n",
    "                 batch_size = args.batch_size, valid_ratio = args.valid_ratio, transform_img=None, transform_mask=None, \n",
    "                 transform_test=None, test_params={'batch_size': args.batch_size, 'shuffle': False})\n",
    "    train_loader, val_loader, test_loader = corro_seg.get_loaders()\n",
    "\n",
    "    # Loss function and optimizer definition\n",
    "    criterion = nn.BCELoss()  # Binary cross-entropy loss\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "\n",
    "    for epoch in tqdm(range(args.num_epochs)):\n",
    "        # Defreezing strategy\n",
    "        if epoch % args.unfreeze_at_epoch == 0:\n",
    "            layers_to_unfreeze = (epoch // args.unfreeze_at_epoch) * args.layers_to_unfreeze_each_time\n",
    "            model.unfreeze_layers(layers_to_unfreeze)\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_iou = 0.0\n",
    "        \n",
    "        for image, mask, well in tqdm(train_loader):\n",
    "            mask = mask.view(-1, 1, 36, 36)\n",
    "            optimizer.zero_grad()\n",
    "            image = image.to(device)  # Move image to device\n",
    "            mask = mask.to(device)  # Move mask to device\n",
    "            outputs = model(image.repeat(1, 3, 1, 1))\n",
    "            loss = criterion(outputs, mask)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * image.size(0)\n",
    "            preds = outputs > args.threshold  # Apply threshold to get binary predictions\n",
    "            train_iou += iou_score(preds, mask).item() * image.size(0)\n",
    "        \n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        train_iou /= len(train_loader.dataset)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_iou = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for image, mask, well in tqdm(val_loader):\n",
    "                mask = mask.view(-1, 1, 36, 36)\n",
    "                image = image.to(device)  # Move image to device\n",
    "                mask = mask.to(device)  # Move mask to device\n",
    "                outputs = model(image.repeat(1, 3, 1, 1))\n",
    "                outputs = outputs.detach()  # Detach outputs from the computation graph\n",
    "                loss = criterion(outputs, mask)\n",
    "                val_loss += loss.item() * image.size(0)\n",
    "                preds = outputs > args.threshold  # Apply threshold to get binary predictions\n",
    "                val_iou += iou_score(preds, mask).item() * image.size(0)\n",
    "        \n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        val_iou /= len(val_loader.dataset)\n",
    "        \n",
    "        # Logging to Weights and Biases\n",
    "        if(args.wandb):\n",
    "            wandb.log({'Train Loss': train_loss, 'Train IoU': train_iou,\n",
    "                    'Validation Loss': val_loss, 'Validation IoU': val_iou}, step=epoch)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{args.num_epochs}, Train Loss: {train_loss:.4f}, Train IoU: {train_iou:.4f}, Validation Loss: {val_loss:.4f}, Validation IoU: {val_iou:.4f}')\n",
    "        \n",
    "    # Testing phase\n",
    "    model.eval()\n",
    "    predicted_masks = []  # List to store predicted masks  \n",
    "    with torch.no_grad():\n",
    "        for image, _ in test_loader:  # Ignore the masks in the test loader\n",
    "            \n",
    "            # Forward pass\n",
    "            image = image.to(device)  # Move image to device\n",
    "            output = model(image.repeat(1, 3, 1, 1)).detach()\n",
    "            pred = output > args.threshold  # Apply threshold to get binary predictions\n",
    "            pred = pred.cpu().numpy()\n",
    "            \n",
    "            # Flatten each 36x36 mask into a 1D array\n",
    "            flattened_mask = pred.reshape(pred.shape[0], -1)\n",
    "            \n",
    "            # Convert predicted masks to numpy arrays\n",
    "            predicted_masks.extend(flattened_mask)\n",
    "    \n",
    "    # Save predicted masks to a CSV file\n",
    "    predicted_masks = np.array(predicted_masks)\n",
    "    df = pd.DataFrame(predicted_masks)\n",
    "    df.to_csv(\"predicted_masks.csv\", index=False)\n",
    "    \n",
    "    print(\"Predicted masks saved to predicted_masks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace(\n",
    "        wandb=True,\n",
    "        experiment_name='test1',\n",
    "        output_dir='wandb',\n",
    "        wandb_id=None,\n",
    "        wandb_entity='lucasgascon',\n",
    "        num_epochs=20,\n",
    "        batch_size=1,\n",
    "        valid_ratio=0.1,\n",
    "        model_name='resnet18',\n",
    "        learning_rate=2e-5,\n",
    "        threshold=0.5,\n",
    "        unfreeze_at_epoch=3,\n",
    "        layers_to_unfreeze_each_time=1,\n",
    "        weight_decay=0.01\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlucasgascon\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/lucasgascon/GitHub/ENS-data-challenge-CorroSeg/wandb/run-20240211_162158-ulidllc8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lucasgascon/corroseg/runs/ulidllc8' target=\"_blank\">test1</a></strong> to <a href='https://wandb.ai/lucasgascon/corroseg' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lucasgascon/corroseg' target=\"_blank\">https://wandb.ai/lucasgascon/corroseg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lucasgascon/corroseg/runs/ulidllc8' target=\"_blank\">https://wandb.ai/lucasgascon/corroseg/runs/ulidllc8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lucasgascon/miniforge3/envs/timeseries/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/lucasgascon/miniforge3/envs/timeseries/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "100%|██████████| 8397/8397 [10:18<00:00, 13.57it/s]\n",
      "100%|██████████| 933/933 [00:18<00:00, 49.17it/s]\n",
      "  5%|▌         | 1/20 [10:37<3:22:00, 637.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 0.2460, Train IoU: 0.9106, Validation Loss: 0.6216, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [09:06<00:00, 15.36it/s]\n",
      "100%|██████████| 933/933 [00:17<00:00, 53.00it/s]\n",
      " 10%|█         | 2/20 [20:02<2:58:23, 594.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Train Loss: 0.2492, Train IoU: 0.9106, Validation Loss: 0.7908, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [09:33<00:00, 14.64it/s]\n",
      "100%|██████████| 933/933 [00:16<00:00, 58.20it/s]\n",
      " 15%|█▌        | 3/20 [29:51<2:47:48, 592.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Train Loss: 0.2492, Train IoU: 0.9106, Validation Loss: 0.5091, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [07:32<00:00, 18.57it/s]\n",
      "100%|██████████| 933/933 [00:17<00:00, 54.74it/s]\n",
      " 20%|██        | 4/20 [37:41<2:24:59, 543.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Train Loss: 0.2454, Train IoU: 0.9106, Validation Loss: 0.5359, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [07:27<00:00, 18.77it/s]\n",
      "100%|██████████| 933/933 [00:16<00:00, 56.39it/s]\n",
      " 25%|██▌       | 5/20 [45:25<2:08:44, 514.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Train Loss: 0.2429, Train IoU: 0.9106, Validation Loss: 0.5057, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [07:35<00:00, 18.45it/s]\n",
      "100%|██████████| 933/933 [00:16<00:00, 55.76it/s]\n",
      " 30%|███       | 6/20 [53:16<1:56:43, 500.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Train Loss: 0.2421, Train IoU: 0.9106, Validation Loss: 0.3463, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [08:53<00:00, 15.74it/s]\n",
      "100%|██████████| 933/933 [00:18<00:00, 51.20it/s]\n",
      " 35%|███▌      | 7/20 [1:02:28<1:52:01, 517.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Train Loss: 0.2403, Train IoU: 0.9106, Validation Loss: 0.3003, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [09:47<00:00, 14.30it/s]\n",
      "100%|██████████| 933/933 [00:17<00:00, 52.50it/s]\n",
      " 40%|████      | 8/20 [1:12:33<1:49:00, 545.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Train Loss: 0.2373, Train IoU: 0.9106, Validation Loss: 0.4949, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [09:50<00:00, 14.22it/s]\n",
      "100%|██████████| 933/933 [00:19<00:00, 48.01it/s]\n",
      " 45%|████▌     | 9/20 [1:22:43<1:43:38, 565.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Train Loss: 0.2361, Train IoU: 0.9106, Validation Loss: 0.3189, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [09:54<00:00, 14.12it/s]\n",
      "100%|██████████| 933/933 [00:17<00:00, 54.21it/s]\n",
      " 50%|█████     | 10/20 [1:32:55<1:36:37, 579.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Train Loss: 0.2356, Train IoU: 0.9106, Validation Loss: 0.2627, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [09:25<00:00, 14.85it/s]\n",
      "100%|██████████| 933/933 [00:16<00:00, 57.14it/s]\n",
      " 55%|█████▌    | 11/20 [1:42:37<1:27:03, 580.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Train Loss: 0.2338, Train IoU: 0.9106, Validation Loss: 0.2640, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8397/8397 [10:00<00:00, 13.99it/s]\n",
      "100%|██████████| 933/933 [00:16<00:00, 57.96it/s]\n",
      " 60%|██████    | 12/20 [1:52:53<1:18:50, 591.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Train Loss: 0.2324, Train IoU: 0.9106, Validation Loss: 0.2577, Validation IoU: 0.9111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 4617/8397 [05:07<04:11, 15.00it/s]\n",
      " 60%|██████    | 12/20 [1:58:01<1:18:40, 590.10s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 46\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     44\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(image\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     45\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, mask)\n\u001b[0;32m---> 46\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     49\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m image\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/timeseries/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/timeseries/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "timeseries",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
